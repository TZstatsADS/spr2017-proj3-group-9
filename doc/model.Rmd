

```{r}

if(!require("gbm")){
  install.packages("gbm")
}

library(gbm)
library(adabag)
library(data.table)
library(dplyr)
library(randomForest)
library(parallel)
library(e1071)
source("../lib/cross_validation.R")
source("../lib/train.R")
source("../lib/test.R")
```



```{r}
sift <- data.frame(t(read.csv("../data/sift_features.csv")))
y<-c(rep(0,1000),rep(1,1000))
s1<-data.frame(cbind(y,sift))
pca <- data.frame(read.csv("../output/feature_pca.csv"))
lasso<- data.frame(read.csv("../output/feature_lasso.csv"))
hog<- data.frame(read.csv("../output/hog.csv"))
hog<- hog[,-1]
lasso<-lasso[,-1]
pca<-pca[,-1]

num<-apply(abs(sign(sift)),1,sum)
```





gbm!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
```{r warning=FALSE}
err<-rep(NA,20)
k<-3
for(i in 1:20){
  err[i]<-cv.function(pca,y,i,k)
}
plot(err)
```

```{r}
 gbmbase <- gbm.fit(x=sift, y=y,
                     n.trees=1000,
                     distribution="bernoulli",
                     interaction.depth=11, 
                     bag.fraction = 0.5,
                     verbose=FALSE)
```



feature

```{r}
ada<-rpart(y~.,data=s1)
n<-names(ada$variable.importance)
select<-as.numeric(substr(n,2,nchar(n)))

k<-3

load("../output/feature0.Rdata")
feature0<-unlist(feature0)

feature<-cbind(pca,sift[,select],lasso,num,feature0)

```






random forest!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!


```{r}
f.test<-cbind(feature,hog)
t1<-Sys.time()
cl <- makeCluster(getOption("cl.cores", 8))
rderr1 <- parLapply(cl, 1:8,  rf.cv.function,X.train=f.test, y.train=y,ntree=1000, K=k)
rderr1<-unlist(rderr1)
plot(rderr1)
t2<-Sys.time()
t2-t1
```




```{r}

rf_fit <- randomForest(x=feature,y=as.factor(y),
                         importance=TRUE, 
                         ntree=1000,
                         nodesize=2)
```

```{r}

```

